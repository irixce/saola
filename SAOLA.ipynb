{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "class Locations:\n",
    "    locations = []\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        reader = csv.reader(open(file_name, 'rb'))\n",
    "        \n",
    "        # Ignore column names\n",
    "        next(reader)\n",
    "\n",
    "        # Proper id numbering with array indices\n",
    "        self.locations.append({'coor': (None, None)})\n",
    "        for line in reader:\n",
    "            tempLoc = {}\n",
    "            lat, _long = line[1], line[2]\n",
    "            tempLoc['coor'] = (lat, _long)\n",
    "            self.locations.append(tempLoc)\n",
    "        \n",
    "\n",
    "loc = Locations('longtitude_latitude2.5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from numpy import arctanh\n",
    "\n",
    "def Z(x, y):\n",
    "    (r, p) = stats.pearsonr(x, y)\n",
    "    r_prime = arctanh(r)\n",
    "    s_r = 1/(sqrt(len(x)-3))\n",
    "    return (r_prime - p)/s_r\n",
    "    \n",
    "def SAOLA(data, label):\n",
    "    markov_blanket = set()\n",
    "    \n",
    "    F = data.predictive_features\n",
    "    C = label\n",
    "    feature_set_past = data.S_t_past\n",
    "    \n",
    "    for f in F:\n",
    "        is_valid = True\n",
    "        if abs(Z(feature, c)) < 1.96:\n",
    "            continue\n",
    "        for y in feature_set_past:\n",
    "            if abs(Z(y, C)) > abs(Z(f,C)) and abs(Z(f, y)) >= 1.96:\n",
    "                is_valid = false\n",
    "                break\n",
    "            if abs(Z(f, C)) > abs(Z(y, C)) and abs(Z(f, y)) >= 1.96:\n",
    "                feature_set_past.remove(y)\n",
    "                \n",
    "        if is_valid:\n",
    "            markov_blanket = feature_set_past | f\n",
    "        \n",
    "    return markov_blanket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    1    1 ..., 5858 5860 5860]\n",
      " [   2    2    1 ..., 5862 5863 5864]\n",
      " [   3    3    1 ..., 5871 5874 5876]\n",
      " ..., \n",
      " [  29  363   12 ..., 5840 5838 5835]\n",
      " [  30  364   12 ..., 5844 5845 5846]\n",
      " [  31  365   12 ..., 5847 5848 5849]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "class Feature_Reader:\n",
    "    file_ext = '.csv'\n",
    "    base_dir = './raw_data/'\n",
    "    \n",
    "    PW = 'pw' # Preciptable water\n",
    "    T850 = 't850' # 850hPa Temperature\n",
    "    U300 = 'u300' # 300 hPa Zonal Wind\n",
    "    U850 = 'u850' # 850 hPa Zonal Wind\n",
    "    V300 = 'v300' # 300 hPa Meridional Wind\n",
    "    V850 = 'v850' # 850 hPa Meridional Wind\n",
    "    Z1000 = 'z1000' # Z1000 hPa Geopotential Height\n",
    "    Z300 = 'z300' # Z300 hPa Geopotential Height\n",
    "    Z500 = 'z500' # Z500 hPa Geopotential Height\n",
    "    \n",
    "    def make_file_path(self,feature, year):\n",
    "        return self.base_dir+feature+'_'+year+self.file_ext\n",
    "    \n",
    "    def get(self, feature, year):\n",
    "        print pd.read_csv(self.make_file_path(feature, str(year)), sep=',').values\n",
    "        \n",
    "reader = Feature_Reader()\n",
    "reader.get(reader.Z500, 2010)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
